{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-17T00:33:51.638247Z",
     "iopub.status.busy": "2025-10-17T00:33:51.637548Z",
     "iopub.status.idle": "2025-10-17T00:34:00.156343Z",
     "shell.execute_reply": "2025-10-17T00:34:00.155709Z",
     "shell.execute_reply.started": "2025-10-17T00:33:51.638210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/Ugenteraan/ResNet-50-CBAM-PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:00.158092Z",
     "iopub.status.busy": "2025-10-17T00:34:00.157689Z",
     "iopub.status.idle": "2025-10-17T00:34:00.170164Z",
     "shell.execute_reply": "2025-10-17T00:34:00.169257Z",
     "shell.execute_reply.started": "2025-10-17T00:34:00.158070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''Convolutional Block Attention Module (CBAM)\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import pooling\n",
    "from torch.nn.modules.flatten import Flatten\n",
    "\n",
    "\n",
    "\n",
    "class Channel_Attention(nn.Module):\n",
    "    '''Channel Attention in CBAM.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        '''Param init and architecture building.\n",
    "        '''\n",
    "\n",
    "        super(Channel_Attention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=channel_in, out_features=channel_in//reduction_ratio),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=channel_in//reduction_ratio, out_features=channel_in)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "    \n",
    "        # média global\n",
    "        avg_pool = torch.mean(x, dim=(2, 3), keepdim=True)\n",
    "    \n",
    "        # máximo global (reduzindo um eixo por vez)\n",
    "        max_pool, _ = torch.max(x, dim=2, keepdim=True)\n",
    "        max_pool, _ = torch.max(max_pool, dim=3, keepdim=True)\n",
    "    \n",
    "        # flatten e passa pelo MLP\n",
    "        avg_out = self.shared_mlp(avg_pool.view(b, c))\n",
    "        max_out = self.shared_mlp(max_pool.view(b, c))\n",
    "    \n",
    "        out = avg_out + max_out\n",
    "        scale = torch.sigmoid(out).view(b, c, 1, 1)\n",
    "    \n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    '''Merge all the channels in a feature map into two separate channels where the first channel is produced by taking the max values from all channels, while the\n",
    "       second one is produced by taking the mean from every channel.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n",
    "\n",
    "\n",
    "class Spatial_Attention(nn.Module):\n",
    "    '''Spatial Attention in CBAM.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        '''Spatial Attention Architecture.\n",
    "        '''\n",
    "\n",
    "        super(Spatial_Attention, self).__init__()\n",
    "\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial_attention = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=kernel_size, stride=1, dilation=1, padding=(kernel_size-1)//2, bias=False)\n",
    "            \n",
    "       \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "        x_compress = self.compress(x)\n",
    "        x_output = self.spatial_attention(x_compress)\n",
    "        scaled = torch.sigmoid(x_output)\n",
    "        return x * scaled\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    '''CBAM architecture.\n",
    "    '''\n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max'], spatial=True):\n",
    "        '''Param init and arch build.\n",
    "        '''\n",
    "        super(CBAM, self).__init__()\n",
    "        self.spatial = spatial\n",
    "\n",
    "        self.channel_attention = Channel_Attention(channel_in=channel_in, reduction_ratio=reduction_ratio, pool_types=pool_types)\n",
    "\n",
    "        if self.spatial:\n",
    "            self.spatial_attention = Spatial_Attention(kernel_size=7)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward Propagation.\n",
    "        '''\n",
    "        x_out = self.channel_attention(x)\n",
    "        if self.spatial:\n",
    "            x_out = self.spatial_attention(x_out)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:00.171240Z",
     "iopub.status.busy": "2025-10-17T00:34:00.170985Z",
     "iopub.status.idle": "2025-10-17T00:34:00.193967Z",
     "shell.execute_reply": "2025-10-17T00:34:00.193151Z",
     "shell.execute_reply.started": "2025-10-17T00:34:00.171221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import Bottleneck\n",
    "\n",
    "class ResNet50_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Carrega o modelo base\n",
    "        self.base = resnet50(weights=\"IMAGENET1K_V1\")\n",
    "        \n",
    "        # Congela as primeiras camadas (opcional, pode descongelar depois)\n",
    "        for param in list(self.base.parameters())[:100]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Adiciona CBAM após as camadas 3 e 4\n",
    "        self.cbam3 = CBAM(channel_in=1024)\n",
    "        self.cbam4 = CBAM(channel_in=2048)\n",
    "        \n",
    "        # Substitui a última camada totalmente conectada\n",
    "        self.base.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Camadas originais até layer3\n",
    "        x = self.base.conv1(x)\n",
    "        x = self.base.bn1(x)\n",
    "        x = self.base.relu(x)\n",
    "        x = self.base.maxpool(x)\n",
    "\n",
    "        x = self.base.layer1(x)\n",
    "        x = self.base.layer2(x)\n",
    "        x = self.base.layer3(x)\n",
    "        x = self.cbam3(x)  # CBAM aqui\n",
    "        x = self.base.layer4(x)\n",
    "        x_conv = self.cbam4(x)  # salvar as features com atenção\n",
    "\n",
    "        x = self.base.avgpool(x_conv)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.base.fc(x)\n",
    "        return x_conv,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:00.195990Z",
     "iopub.status.busy": "2025-10-17T00:34:00.195778Z",
     "iopub.status.idle": "2025-10-17T00:34:00.302211Z",
     "shell.execute_reply": "2025-10-17T00:34:00.301413Z",
     "shell.execute_reply.started": "2025-10-17T00:34:00.195966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = '/kaggle/input/cub-200-2011/images'\n",
    "num_classes = 200\n",
    "batch_size = 16\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:00.303348Z",
     "iopub.status.busy": "2025-10-17T00:34:00.303067Z",
     "iopub.status.idle": "2025-10-17T00:34:00.315760Z",
     "shell.execute_reply": "2025-10-17T00:34:00.315100Z",
     "shell.execute_reply.started": "2025-10-17T00:34:00.303327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(448),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:00.316819Z",
     "iopub.status.busy": "2025-10-17T00:34:00.316538Z",
     "iopub.status.idle": "2025-10-17T00:34:15.163797Z",
     "shell.execute_reply": "2025-10-17T00:34:15.162929Z",
     "shell.execute_reply.started": "2025-10-17T00:34:00.316764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:15.164995Z",
     "iopub.status.busy": "2025-10-17T00:34:15.164734Z",
     "iopub.status.idle": "2025-10-17T00:34:16.706290Z",
     "shell.execute_reply": "2025-10-17T00:34:16.705659Z",
     "shell.execute_reply.started": "2025-10-17T00:34:15.164967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 184MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = ResNet50_CBAM(num_classes=200)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:16.707339Z",
     "iopub.status.busy": "2025-10-17T00:34:16.707069Z",
     "iopub.status.idle": "2025-10-17T00:34:16.712525Z",
     "shell.execute_reply": "2025-10-17T00:34:16.711655Z",
     "shell.execute_reply.started": "2025-10-17T00:34:16.707314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:16.713614Z",
     "iopub.status.busy": "2025-10-17T00:34:16.713324Z",
     "iopub.status.idle": "2025-10-17T00:34:16.728014Z",
     "shell.execute_reply": "2025-10-17T00:34:16.727369Z",
     "shell.execute_reply.started": "2025-10-17T00:34:16.713570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nÉpoca {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    x_conv, outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "                # Salvar melhor modelo\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    #if Config.SAVE_MODEL_DIR is not None:\n",
    "                     #   save_path = os.path.join(Config.SAVE_MODEL_DIR, \"best_resnet50_cub_fullfinetune.pth\")\n",
    "                    #else:\n",
    "                    save_path = \"best_resnet50_cub_fullfinetune.pth\"\n",
    "\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(f\"\\nTreinamento concluído! Melhor acurácia de validação: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T00:34:16.730778Z",
     "iopub.status.busy": "2025-10-17T00:34:16.730148Z",
     "iopub.status.idle": "2025-10-17T01:42:43.626241Z",
     "shell.execute_reply": "2025-10-17T01:42:43.625285Z",
     "shell.execute_reply.started": "2025-10-17T00:34:16.730758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Época 1/15\n",
      "------------------------------\n",
      "train Loss: 5.2325 Acc: 0.0228\n",
      "val Loss: 4.9626 Acc: 0.1129\n",
      "\n",
      "Época 2/15\n",
      "------------------------------\n",
      "train Loss: 4.8208 Acc: 0.1042\n",
      "val Loss: 4.2306 Acc: 0.1988\n",
      "\n",
      "Época 3/15\n",
      "------------------------------\n",
      "train Loss: 4.3376 Acc: 0.1651\n",
      "val Loss: 3.6891 Acc: 0.2881\n",
      "\n",
      "Época 4/15\n",
      "------------------------------\n",
      "train Loss: 3.9192 Acc: 0.2387\n",
      "val Loss: 3.1690 Acc: 0.3749\n",
      "\n",
      "Época 5/15\n",
      "------------------------------\n",
      "train Loss: 3.5738 Acc: 0.3157\n",
      "val Loss: 2.7790 Acc: 0.4516\n",
      "\n",
      "Época 6/15\n",
      "------------------------------\n",
      "train Loss: 3.2864 Acc: 0.3753\n",
      "val Loss: 2.5399 Acc: 0.5118\n",
      "\n",
      "Época 7/15\n",
      "------------------------------\n",
      "train Loss: 3.0547 Acc: 0.4279\n",
      "val Loss: 2.2453 Acc: 0.5569\n",
      "\n",
      "Época 8/15\n",
      "------------------------------\n",
      "train Loss: 2.8518 Acc: 0.4615\n",
      "val Loss: 2.0415 Acc: 0.5830\n",
      "\n",
      "Época 9/15\n",
      "------------------------------\n",
      "train Loss: 2.6683 Acc: 0.4935\n",
      "val Loss: 1.8543 Acc: 0.6209\n",
      "\n",
      "Época 10/15\n",
      "------------------------------\n",
      "train Loss: 2.5139 Acc: 0.5155\n",
      "val Loss: 1.7097 Acc: 0.6466\n",
      "\n",
      "Época 11/15\n",
      "------------------------------\n",
      "train Loss: 2.3642 Acc: 0.5494\n",
      "val Loss: 1.6135 Acc: 0.6714\n",
      "\n",
      "Época 12/15\n",
      "------------------------------\n",
      "train Loss: 2.2407 Acc: 0.5727\n",
      "val Loss: 1.4708 Acc: 0.6816\n",
      "\n",
      "Época 13/15\n",
      "------------------------------\n",
      "train Loss: 2.1135 Acc: 0.6003\n",
      "val Loss: 1.3863 Acc: 0.7148\n",
      "\n",
      "Época 14/15\n",
      "------------------------------\n",
      "train Loss: 2.0108 Acc: 0.6121\n",
      "val Loss: 1.3055 Acc: 0.7216\n",
      "\n",
      "Época 15/15\n",
      "------------------------------\n",
      "train Loss: 1.9039 Acc: 0.6356\n",
      "val Loss: 1.2159 Acc: 0.7409\n",
      "\n",
      "Treinamento concluído! Melhor acurácia de validação: 0.7409\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8460535,
     "sourceId": 13341731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
